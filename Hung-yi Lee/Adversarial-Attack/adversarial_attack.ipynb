{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#作业要求： 接触adversarial attack 一个简单的 attack approach: FGSM\n",
    "#代码中所用到的资源需自行提前下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引入库\n",
    "import os\n",
    "# 读取 label.csv\n",
    "import pandas as pd\n",
    "# 读取图片\n",
    "from PIL import Image\n",
    "# 支持大量的维度数组和矩阵运算\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# Loss function\n",
    "import torch.nn.functional as F\n",
    "# 读取资料\n",
    "import torchvision.datasets as datasets\n",
    "# 主要用来将自定义的数据读取接口的输出或者pytorch已有的数据读取接口的输入按照batch_size封装成Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# 载入预训练模型\n",
    "import torchvision.models as models\n",
    "# 将资料装换成符合预训练模型的形式\n",
    "import torchvision.transforms as transforms\n",
    "# 显示图片\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 表示将torch.Tensor分配到的设备的对象为cuda\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取资料库\n",
    "# 實作一個繼承 torch.utils.data.Dataset 的 Class 來讀取圖片\n",
    "class Adverdataset(Dataset):\n",
    "    def __init__(self, root, label, transforms):\n",
    "\n",
    "\n",
    "        # 圖片所在的資料夾\n",
    "        self.root = root\n",
    "        # 由 main function 傳入的 label\n",
    "        self.label = torch.from_numpy(label).long()\n",
    "        # 由 Attacker 傳入的 transforms 將輸入的圖片轉換成符合預訓練模型的形式\n",
    "        self.transforms = transforms\n",
    "        # 圖片檔案名稱的 list\n",
    "        self.fnames = []\n",
    "\n",
    "        # 主要实现图片名称若列宽不足3位，则用数字0填充到3位\n",
    "        for i in range(200):\n",
    "            self.fnames.append(\"{:03d}\".format(i))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 利用路徑讀取圖片\n",
    "        img = Image.open(os.path.join(self.root, self.fnames[idx] + '.png'))\n",
    "        # 將輸入的圖片轉換成符合預訓練模型的形式\n",
    "        img = self.transforms(img)\n",
    "        # 圖片相對應的 label\n",
    "        label = self.label[idx]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 由於已知這次的資料總共有 200 張圖片 所以回傳 200\n",
    "        return 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入模型并执行FGSM攻击\n",
    "class Attacker:\n",
    "    def __init__(self, img_dir, label):\n",
    "        # 讀入預訓練模型 vgg16\n",
    "        self.model = models.vgg16(pretrained = True)\n",
    "        # 模型将在GPU上运行\n",
    "        self.model.cuda()\n",
    "        # 固定BatchNoramalization 和 Dropout 层,使得偏置参数不随着发生变化\n",
    "        self.model.eval()\n",
    "        # 使用imagenet 的平均值和标准差进行正则化\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        # 把圖片 normalize 到 0~1 之間 mean 0 variance 1\n",
    "        self.normalize = transforms.Normalize(self.mean, self.std, inplace=False)\n",
    "        transform = transforms.Compose([                \n",
    "                        transforms.Resize((224, 224), interpolation=3),\n",
    "                        transforms.ToTensor(),\n",
    "                        self.normalize\n",
    "                    ])\n",
    "        \n",
    "        # 利用 Adverdataset 這個 class 讀取資料，将标签值和训练值给dataset\n",
    "        self.dataset = Adverdataset('./data/images', label, transform)\n",
    "        \n",
    "        # __init__中的几个重要的输入：1、dataset，这个就是PyTorch已有的数据读取接口\n",
    "        #（比如torchvision.datasets.ImageFolder）或者自定义的数据接口的输出，\n",
    "        # 该输出要么是torch.utils.data.Dataset类的对象，要么是继承自torch.utils.data.Dataset类的自定义类的对象。\n",
    "        # 2、batch_size，根据具体情况设置即可。3、shuffle(打乱数据)，一般在训练数据中会采用\n",
    "        self.loader = torch.utils.data.DataLoader(\n",
    "                self.dataset,\n",
    "                batch_size = 1,\n",
    "                shuffle = False)\n",
    "        \n",
    "\n",
    "    # FGSM 攻擊\n",
    "    def fgsm_attack(self, image, epsilon, data_grad):#epsilon是后面自己设置数，体现噪声的强度\n",
    "\n",
    "        # 找出 gradient 的方向\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        # 將圖片加上 gradient 方向乘上 epsilon 的 noise\n",
    "        perturbed_image = image + epsilon * sign_data_grad#生成有噪音的图片\n",
    "        return perturbed_image\n",
    "    \n",
    "    def attack(self, epsilon):\n",
    "\n",
    "        # 存下一些成功攻擊後的圖片 以便之後顯示\n",
    "        adv_examples = []\n",
    "        wrong, fail, success = 0, 0, 0\n",
    "        for (data, target) in self.loader:\n",
    "            data, target = data.to(device), target.to(device)#把数据转化为cpu,或者GPU的数据类型\n",
    "            data_raw = data;\n",
    "            data.requires_grad = True#自动计算梯度\n",
    "\n",
    "            # 將圖片丟入 model 進行測試 得出相對應的 class\n",
    "            output = self.model(data)\n",
    "            init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "            # 如果 class 錯誤 就不進行攻擊\n",
    "            if init_pred.item() != target.item():\n",
    "                wrong += 1\n",
    "                continue\n",
    "            \n",
    "            # 如果 class 正確 就開始計算 gradient 進行 FGSM 攻擊\n",
    "            loss = F.nll_loss(output, target)\n",
    "            self.model.zero_grad()#梯度置零，防止叠加\n",
    "            loss.backward()\n",
    "            data_grad = data.grad.data\n",
    "            perturbed_data = self.fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "            # 再將加入 noise 的圖片丟入 model 進行測試 得出相對應的 class        \n",
    "            output = self.model(perturbed_data)\n",
    "            final_pred = output.max(1, keepdim=True)[1]\n",
    "          \n",
    "            if final_pred.item() == target.item():\n",
    "                # 辨識結果還是正確 攻擊失敗\n",
    "                fail += 1\n",
    "            else:\n",
    "                # 辨識結果失敗 攻擊成功\n",
    "                success += 1\n",
    "                # 將攻擊成功的圖片存入\n",
    "                if len(adv_examples) < 5:\n",
    "                  adv_ex = perturbed_data * torch.tensor(self.std, device = device).view(3, 1, 1) + torch.tensor(self.mean, device = device).view(3, 1, 1)\n",
    "                  adv_ex = adv_ex.squeeze().detach().cpu().numpy() \n",
    "                  #squeeze 数据的维度进行压缩，去掉维数为1的的维度，比如是一行或者一列这种，一个一行三列（1,3）的数去掉第一个维数为一的维度之后就变成（3）行\n",
    "                  data_raw = data_raw * torch.tensor(self.std, device = device).view(3, 1, 1) + torch.tensor(self.mean, device = device).view(3, 1, 1)\n",
    "                  data_raw = data_raw.squeeze().detach().cpu().numpy()\n",
    "                  adv_examples.append( (init_pred.item(), final_pred.item(), data_raw , adv_ex) )        \n",
    "        final_acc = (fail / (wrong + success + fail))\n",
    "        \n",
    "        print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\\n\".format(epsilon, fail, len(self.loader), final_acc))\n",
    "        return adv_examples, final_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\BMDZ/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde139130dd34e6e9d875cad35a56d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 执行攻击 并显示攻击成功率\n",
    "if __name__ == '__main__':\n",
    "    # 讀入圖片相對應的 label\n",
    "    df = pd.read_csv(\"./data/labels.csv\")\n",
    "    df = df.loc[:, 'TrueLabel'].to_numpy()\n",
    "    label_name = pd.read_csv(\"./data/categories.csv\")\n",
    "    label_name = label_name.loc[:, 'CategoryName'].to_numpy()\n",
    "    # new 一個 Attacker class\n",
    "    attacker = Attacker('./data/images', df)\n",
    "    # 要嘗試的 epsilon\n",
    "    epsilons = [0.1, 0.01]\n",
    "\n",
    "    accuracies, examples = [], []\n",
    "\n",
    "    # 進行攻擊 並存起正確率和攻擊成功的圖片\n",
    "    for eps in epsilons:\n",
    "        ex, acc = attacker.attack(eps)\n",
    "        accuracies.append(acc)\n",
    "        examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示FGSM产生的图片\n",
    "cnt = 0\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(len(epsilons)):#遍历之前eps里的元素，idx值为0，1\n",
    "\n",
    "    for j in range(len(examples[i])):#遍历样本值，\n",
    "        cnt += 1\n",
    "\n",
    "        #subplot(nrows, ncols, plot_number)\n",
    "        #或者写成subplot(nrows ncols plot_number)也行（中间不用逗号，前提是只能是三位数）\n",
    "        #这个函数用来表示把figure分成nrows*ncols的子图表示，\n",
    "        #nrows：子图的行数\n",
    "        #ncols：子图的列数\n",
    "        #plot_number 索引值，表示把图画在第plot_number个位置（从左下角到右上角）\n",
    "        plt.subplot(len(epsilons),len(examples[0]) * 2,cnt)\n",
    "        plt.xticks([], [])#坐标轴变名用法\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "\n",
    "        orig,adv,orig_img, ex = examples[i][j]\n",
    "\n",
    "        # plt.title(\"{} -> {}\".format(orig, adv))\n",
    "        plt.title(\"original: {}\".format(label_name[orig].split(',')[0]))\n",
    "        orig_img = np.transpose(orig_img, (1, 2, 0))#转置(0,1,2)->(1, 2, 0)\n",
    "        plt.imshow(orig_img)\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]) * 2,cnt)\n",
    "        plt.title(\"adversarial: {}\".format(label_name[adv].split(',')[0]))\n",
    "        ex = np.transpose(ex, (1, 2, 0))\n",
    "        plt.imshow(ex)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
